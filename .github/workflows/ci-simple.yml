# Reliable API Test Automation
name: API Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: false
        default: 'smoke'
        type: choice
        options:
        - smoke
        - regression
        - all

jobs:
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up JDK 17
      uses: actions/setup-java@v4
      with:
        java-version: '17'
        distribution: 'temurin'

    - name: Cache Maven dependencies
      uses: actions/cache@v4
      with:
        path: ~/.m2
        key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
        restore-keys: ${{ runner.os }}-m2

    - name: Run API Tests
      run: |
        SUITE=${{ github.event.inputs.test_suite || 'smoke' }}
        echo "Running $SUITE tests..."
        
        mvn clean test \
          -Denv=dev \
          -P${SUITE},ci \
          --batch-mode \
          --no-transfer-progress
      env:
        MAVEN_OPTS: "-Xmx1536m -Xms512m"

    - name: Display Test Results
      if: always()
      run: |
        echo "=== Test Execution Complete ===" 
        
        # Add to GitHub Step Summary
        echo "## 🧪 API Test Results" >> $GITHUB_STEP_SUMMARY
        echo "**Environment:** dev" >> $GITHUB_STEP_SUMMARY
        echo "**Test Suite:** ${{ github.event.inputs.test_suite || 'smoke' }}" >> $GITHUB_STEP_SUMMARY
        echo "**Date:** $(date)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -d "target/surefire-reports" ]; then
          echo "✅ Test reports generated"
          
          # Simple test count
          XML_FILES=$(find target/surefire-reports -name "TEST-*.xml" 2>/dev/null || echo "")
          if [ -n "$XML_FILES" ]; then
            echo "📊 Test report files found:"
            ls -la target/surefire-reports/TEST-*.xml || true
            
            # Parse test results for summary
            TOTAL_TESTS=0
            FAILURES=0
            ERRORS=0
            SKIPPED=0
            
            for file in target/surefire-reports/TEST-*.xml; do
              if [ -f "$file" ]; then
                # Extract numbers from XML attributes
                TESTS=$(grep -o 'tests="[0-9]*"' "$file" | grep -o '[0-9]*' || echo "0")
                FAILS=$(grep -o 'failures="[0-9]*"' "$file" | grep -o '[0-9]*' || echo "0")
                ERRS=$(grep -o 'errors="[0-9]*"' "$file" | grep -o '[0-9]*' || echo "0")
                SKIP=$(grep -o 'skipped="[0-9]*"' "$file" | grep -o '[0-9]*' || echo "0")
                
                TOTAL_TESTS=$((TOTAL_TESTS + ${TESTS:-0}))
                FAILURES=$((FAILURES + ${FAILS:-0}))
                ERRORS=$((ERRORS + ${ERRS:-0}))
                SKIPPED=$((SKIPPED + ${SKIP:-0}))
              fi
            done
            
            PASSED=$((TOTAL_TESTS - FAILURES - ERRORS - SKIPPED))
            
            # Add results table to GitHub Summary
            echo "### Test Results Summary" >> $GITHUB_STEP_SUMMARY
            echo "| Status | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| 📊 **Total Tests** | $TOTAL_TESTS |" >> $GITHUB_STEP_SUMMARY
            echo "| ✅ **Passed** | $PASSED |" >> $GITHUB_STEP_SUMMARY
            echo "| ❌ **Failed** | $FAILURES |" >> $GITHUB_STEP_SUMMARY
            echo "| 🔥 **Errors** | $ERRORS |" >> $GITHUB_STEP_SUMMARY
            echo "| ⏭️ **Skipped** | $SKIPPED |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Add status badge
            if [ "$FAILURES" -eq 0 ] && [ "$ERRORS" -eq 0 ]; then
              echo "### 🎉 **All Tests Passed!** ✅" >> $GITHUB_STEP_SUMMARY
            else
              echo "### ⚠️ **Some Tests Failed** ❌" >> $GITHUB_STEP_SUMMARY
              echo "- Failed: $FAILURES" >> $GITHUB_STEP_SUMMARY
              echo "- Errors: $ERRORS" >> $GITHUB_STEP_SUMMARY
            fi
            
            # Console output for logs
            echo "📊 Test Summary: Total=$TOTAL_TESTS, Passed=$PASSED, Failed=$FAILURES, Errors=$ERRORS, Skipped=$SKIPPED"
          else
            echo "⚠️ No XML test reports found"
            echo "⚠️ No test reports found" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "❌ No surefire-reports directory found"
          echo "❌ No test execution detected" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Show any log files
        if [ -d "logs" ]; then
          echo "📝 Log files available:"
          ls -la logs/ || true
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📁 **Log files available in artifacts**" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Upload Test Artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results
        path: |
          target/surefire-reports/
          target/allure-results/
          test-output/
          logs/
        retention-days: 5
        if-no-files-found: ignore

    - name: Validate Test Results
      if: always()
      run: |
        echo "=== Validating Test Results ==="
        
        # Check if surefire reports directory exists
        if [ ! -d "target/surefire-reports" ]; then
          echo "❌ No surefire-reports directory found"
          exit 1
        fi
        
        # Check if any XML test reports exist
        XML_COUNT=$(find target/surefire-reports -name "TEST-*.xml" 2>/dev/null | wc -l)
        if [ "$XML_COUNT" -eq 0 ]; then
          echo "❌ No XML test reports found"
          exit 1
        fi
        
        echo "✅ Found $XML_COUNT test report file(s)"
        
        # Check for test failures or errors
        FAILURE_COUNT=0
        ERROR_COUNT=0
        
        for file in target/surefire-reports/TEST-*.xml; do
          if [ -f "$file" ]; then
            # Extract failure and error counts
            FAILURES=$(grep -o 'failures="[0-9]*"' "$file" | grep -o '[0-9]*' || echo "0")
            ERRORS=$(grep -o 'errors="[0-9]*"' "$file" | grep -o '[0-9]*' || echo "0")
            
            FAILURE_COUNT=$((FAILURE_COUNT + ${FAILURES:-0}))
            ERROR_COUNT=$((ERROR_COUNT + ${ERRORS:-0}))
          fi
        done
        
        echo "Test Results: Failures=$FAILURE_COUNT, Errors=$ERROR_COUNT"
        
        if [ "$FAILURE_COUNT" -gt 0 ]; then
          echo "❌ Found $FAILURE_COUNT test failure(s)"
          exit 1
        elif [ "$ERROR_COUNT" -gt 0 ]; then
          echo "❌ Found $ERROR_COUNT test error(s)"
          exit 1
        else
          echo "✅ All tests passed successfully!"
        fi

    - name: Create Status Check
      if: always()
      uses: actions/github-script@v7
      with:
        script: |
          // Only create status for non-PR events to avoid permission issues
          if (context.eventName !== 'pull_request') {
            try {
              // Read test results
              const fs = require('fs');
              const path = require('path');
              
              let status = 'success';
              let description = 'All tests passed';
              
              try {
                // Check if test reports exist
                const reportsDir = 'target/surefire-reports';
                if (fs.existsSync(reportsDir)) {
                  const files = fs.readdirSync(reportsDir).filter(f => f.startsWith('TEST-') && f.endsWith('.xml'));
                  
                  if (files.length > 0) {
                    // Simple check for failures/errors in filenames or basic content
                    let hasFailures = false;
                    for (const file of files) {
                      const content = fs.readFileSync(path.join(reportsDir, file), 'utf8');
                      if (content.includes('failures="') && !content.includes('failures="0"')) {
                        hasFailures = true;
                        break;
                      }
                      if (content.includes('errors="') && !content.includes('errors="0"')) {
                        hasFailures = true;
                        break;
                      }
                    }
                    
                    if (hasFailures) {
                      status = 'failure';
                      description = 'Some tests failed';
                    } else {
                      description = `All tests passed (${files.length} test files)`;
                    }
                  } else {
                    status = 'failure';
                    description = 'No test reports found';
                  }
                } else {
                  status = 'failure';
                  description = 'No test execution detected';
                }
              } catch (e) {
                console.log('Error reading test results:', e.message);
                status = 'error';
                description = 'Error reading test results';
              }
              
              console.log(`Creating status: ${status} - ${description}`);
              
            } catch (error) {
              console.log('Status creation skipped:', error.message);
            }
          } else {
            console.log('Skipping status creation for pull request');
          }
